{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89517cca",
   "metadata": {},
   "source": [
    "# CIFAR 10 WITH CNN\n",
    "\n",
    "This model classifies each image into one of 10 categories. If you want to run code, you need to download images and labels from [this link](https://www.kaggle.com/c/cifar-10).\n",
    "\n",
    "Some of the hyperparameters were tuned using Optuna with lower number of epochs - check file tunable-model.py for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c5527",
   "metadata": {},
   "source": [
    "## 1. Import libraries, set few properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4705e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from matplotlib import image\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# big batch_size can cause generalization problems:\n",
    "# https://stats.stackexchange.com/a/236393\n",
    "\n",
    "# tools for resources monitoring:\n",
    "# nvidia-smi -l 1\n",
    "# free -m -l -s 1\n",
    "\n",
    "# batch_size = 128 could be better, but I haven't got enough gpu memory\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33bafd",
   "metadata": {},
   "source": [
    "## 2. Load and prepare all images from a directory\n",
    "\n",
    "10% of the data will be selected as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a216d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded images: 50000\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "filesnames = listdir('train')\n",
    "\n",
    "\n",
    "def sortKey(filename):\n",
    "    dotindex = filename.index(\".\")\n",
    "    return int(filename[:dotindex])\n",
    "\n",
    "\n",
    "filesnames.sort(key=sortKey)\n",
    "for filename in filesnames:\n",
    "    # load image\n",
    "    img_data = image.imread('train/' + filename)\n",
    "    # store loaded image\n",
    "    X.append(img_data)\n",
    "print(\"Number of loaded images:\", len(X))\n",
    "X = np.array(X)\n",
    "\n",
    "y_raw = pd.read_csv(\"trainLabels.csv\")[\"label\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_raw)\n",
    "y_le = le.transform(y_raw)\n",
    "y = keras.utils.np_utils.to_categorical(y_le, 10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ecd68",
   "metadata": {},
   "source": [
    "## 3. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6dbce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 30, 30, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 26, 26, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 13, 13, 256)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 11, 11, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 11, 11, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 9, 9, 1024)        4719616   \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 9, 9, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 9, 9, 1024)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 82944)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               42467840  \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,890,634\n",
      "Trainable params: 48,885,770\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/102483/difference-between-relu-elu-and-leaky-relu-their-pros-and-cons-majorly\n",
    "# relu -> x if x>0 else 0\n",
    "# leaky relu -> x if x>0 else 0.01x\n",
    "# elu -> x if x>0 else 0.01 * (exp(x) - 1)\n",
    "activation_function = keras.layers.LeakyReLU(alpha=0.01)\n",
    "\n",
    "# https://stackoverflow.com/questions/36243536/what-is-the-number-of-filter-in-cnn\n",
    "# \"filters\" param sets the maximum number of filters in layer\n",
    "# each filter creates new feature map (much higher complexity!)\n",
    "conv_two_exp = 7\n",
    "first_layer_filters = 2 ** conv_two_exp\n",
    "kernel_unit = 3\n",
    "kernel_size = (kernel_unit, kernel_unit)\n",
    "kernel_initializer = 'he_uniform'\n",
    "\n",
    "model.add(Conv2D(first_layer_filters, kernel_size=kernel_size,\n",
    "                 activation=activation_function,\n",
    "                 input_shape=input_shape, kernel_initializer=kernel_initializer))\n",
    "# https://www.baeldung.com/cs/batch-normalization-cnn\n",
    "# BatchNormalization - normalizes data between mini-batches. It allows using higher learning rate.\n",
    "# Subtract mean of neurons output and divide by standard deviation.\n",
    "# \"each feature map will have a single mean and standard deviation, used on all the features it contains\"\n",
    "model.add(BatchNormalization())\n",
    "model.add(\n",
    "    Conv2D(first_layer_filters, kernel_size, activation=activation_function, kernel_initializer=kernel_initializer))\n",
    "model.add(BatchNormalization())\n",
    "dropout1 = 0.07500704262884543\n",
    "model.add(Dropout(dropout1))\n",
    "\n",
    "# 2x more filters in each next Conv2D layer\n",
    "model.add(\n",
    "    Conv2D(first_layer_filters * 2, kernel_size, activation=activation_function, kernel_initializer=kernel_initializer))\n",
    "\n",
    "# MaxPooling2D Reduces number of trainable parameters\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "dropout2 = 0.1349281039679955\n",
    "model.add(Dropout(dropout2))\n",
    "model.add(\n",
    "    Conv2D(first_layer_filters * 4, kernel_size, activation=activation_function, kernel_initializer=kernel_initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(\n",
    "    Conv2D(first_layer_filters * 8, kernel_size, activation=activation_function, kernel_initializer=kernel_initializer))\n",
    "model.add(BatchNormalization())\n",
    "dropout3 = 0.12798787648693688\n",
    "model.add(Dropout(dropout3))\n",
    "model.add(Flatten())\n",
    "dense_two_exp = 9\n",
    "dense_units = 2 ** dense_two_exp\n",
    "model.add(Dense(dense_units, activation=activation_function))\n",
    "model.add(BatchNormalization())\n",
    "dropout4 = 0.23270556518901153\n",
    "model.add(Dropout(dropout4))\n",
    "model.add(Dense(dense_units / 4, activation=activation_function))\n",
    "model.add(BatchNormalization())\n",
    "dropout5 = 0.4304300824505963\n",
    "model.add(Dropout(dropout5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Adam optimizer tunes learning rate in next epochs\n",
    "learning_rate = 0.0009766910468362844\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ed899",
   "metadata": {},
   "source": [
    "## 4. Prepare the data augmentation generator and early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8085b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.2851945624723854,  # Randomly zoom image\n",
    "    shear_range=0.42664072982759615,  # shear angle in counter-clockwise direction in degrees\n",
    "    width_shift_range=0.14234862104307688,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.12363487226276715,  # randomly shift images vertically (fraction of total height)\n",
    "    vertical_flip=False,\n",
    "    horizontal_flip=True)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                        mode=\"max\", patience=100,\n",
    "                                        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa55bf",
   "metadata": {},
   "source": [
    "## 5. Fit the model and save it to the file\n",
    "\n",
    "This cell is not executed, because it takes a lot of time. I trained the model outside of this notebook, and here I'll only load it from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "#                  epochs=epochs,\n",
    "#                  verbose=1,\n",
    "#                  validation_data=(X_test, y_test),\n",
    "#                  callbacks=[earlystopping])\n",
    "\n",
    "# model.save('cnn-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4bcf83",
   "metadata": {},
   "source": [
    "## 6. Evaluate the model on train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0936330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2764671742916107\n",
      "Test accuracy: 0.9351999759674072\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('cnn-model')\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba33f8",
   "metadata": {},
   "source": [
    "About 93.5% of accuracy - it looks not so bad. Now let's check the score on new data from Kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360e87e",
   "metadata": {},
   "source": [
    "## 7. Prepare submission for competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b419f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded images: 300000\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "path = 'competitiona-images/test'\n",
    "filesnames = listdir(path)\n",
    "\n",
    "def sortKey(filename):\n",
    "    dotindex = filename.index(\".\")\n",
    "    return int(filename[:dotindex])\n",
    "\n",
    "\n",
    "filesnames.sort(key=sortKey)\n",
    "for filename in filesnames:\n",
    "    # load image\n",
    "    img_data = image.imread(path + '/' + filename)\n",
    "    # store loaded image\n",
    "    X.append(img_data)\n",
    "print(\"Number of loaded images:\", len(X))\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "y_pred = model.predict(X, batch_size=32)\n",
    "y_pred_classes = np.argmax(y_pred,axis=1)\n",
    "y_pred_le = le.inverse_transform(y_pred_classes)\n",
    "\n",
    "result = pd.DataFrame(filesnames, columns=[\"id\"])\n",
    "result[\"id\"] = result[\"id\"].str.replace(\".png\", \"\")\n",
    "result[\"id\"] = pd.to_numeric(result[\"id\"])\n",
    "result[\"label\"] = y_pred_le\n",
    "result = result.sort_values(\"id\")\n",
    "\n",
    "result.to_csv(\"full_res.csv\", index=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e41e9",
   "metadata": {},
   "source": [
    "Predictions have been made. Now we need to send full_res.csv file as \"late submission\" for competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400dbf9",
   "metadata": {},
   "source": [
    "![Results from competition](late_submission.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2bc75",
   "metadata": {},
   "source": [
    "The competition's score is only about 1 percentage point lower than the one from train-test split, so the generalization of the model is at a decent level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
